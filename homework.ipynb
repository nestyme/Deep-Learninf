{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home work 5: Basic Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На семинаре вы написали нейронную сеть. Настало время ее использовать!  В этом ноутбуке вы создадите нейронную сеть и методом градиентного спуска обучите ее распознавать цифры.\n",
    "\n",
    "В этой домашней работе вам потребуются три ноутбука: **modules.ipynb**, **main.ipynb**, с помощью которого вы сможете отладить реализацию методов в modules.ipynb, и **nn.ipynb** (этот ноутбук). Сдать нужно все три ноутбука."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from time import time, sleep\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решите раздел backward в main.ipynb, убедитесь что все ячейки отрабатывают без ошибок и что относительная погрешность там же не превышает 1e-4 для каждого теста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run modules.ipynb\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизация методом стохастического градиентного спуска уже написана за вас."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(x, dx, config):\n",
    "    \"\"\"        \n",
    "        config:\n",
    "            - learning_rate\n",
    "    \"\"\"\n",
    "    \n",
    "    for cur_layer_x, cur_layer_dx in zip(x,dx): \n",
    "        for cur_x, cur_dx in zip(cur_layer_x,cur_layer_dx):\n",
    "            cur_x -=  config['learning_rate'] * cur_dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте еще раз протестируем наши модули на искуственно сгенерированной выборке.\n",
    "\n",
    "В этом блоке вам не надо ничего реализовывать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate some data\n",
    "N = 500\n",
    "\n",
    "X1 = np.random.randn(N,2) + np.array([2,2])\n",
    "X2 = np.random.randn(N,2) + np.array([-2,-2])\n",
    "\n",
    "Y = np.concatenate([np.ones(N),np.zeros(N)])[:,None]\n",
    "Y = np.hstack([Y, 1-Y])\n",
    "\n",
    "X = np.vstack([X1,X2])\n",
    "plt.scatter(X[:,0],X[:,1], c = Y[:,0], edgecolors= 'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы решаем задачу многоклассовой классификации с двумя классами. Истинный вектор для каждого объекта - это вектор из 0 и 1, в котором 1 стоит на том месте, какому классу принадлежит объект. Хочется чтобы сеть выдавала набор чисел, каждое из которых являлось бы степенью уверенности сети в принадлежности объекта соответствующему классу (так вектор (0.9, 0.1) означал бы что сеть считает, что объект скорее всего принадлежит нулевому классу, а не первому). Давайте зададим пару ограничений на уверенность:\n",
    "\n",
    "1) Наша уверенность не может быть отрицательной. \n",
    "\n",
    "2) В сумме наша уверенность по всем объектам должна давать 1.\n",
    "\n",
    "Набор чисел на которых выполнены эти два свойства называют распределением вероятностей.\n",
    "\n",
    "Сеть может выдавать отрицательные числа, не говоря о том, что сумма предсказаний для объекта может быть больше единицы. Чтобы получить из произвольного набора чисел распределение вероятностей придумали функцию **SoftMax**. Её формула: $$output_i = \\frac{e^{input_i}}{\\sum_n e^{input_n}}.$$\n",
    "\n",
    "Что он делает - это переводит входной вектор в вектор вероятностей (неотрицательных чисел в сумме дающих единицу)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Sequential()\n",
    "net.add(Linear(2, 2))\n",
    "net.add(SoftMax())\n",
    "\n",
    "criterion = MSECriterion()\n",
    "\n",
    "print(net)\n",
    "\n",
    "# Попробуйте что-нибудь вроде этого:\n",
    "\n",
    "# net = Sequential()\n",
    "# net.add(Linear(2, 4))\n",
    "# net.add(Sigmoid())\n",
    "# net.add(Linear(4, 2))\n",
    "# net.add(SoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer_config = {'learning_rate' : 1e-2}\n",
    "optimizer_state = {}\n",
    "\n",
    "n_epoch = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# генератор минибатчей\n",
    "def get_batches(dataset, batch_size):\n",
    "    X, Y = dataset\n",
    "    n_samples = X.shape[0]\n",
    "        \n",
    "    # после каждой эпохи мы заново перемешиваем объекты тренировочной выборки\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_idx = indices[start:end]\n",
    "    \n",
    "        yield X[batch_idx], Y[batch_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обучим модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    for x_batch, y_batch in get_batches((X, Y), batch_size):\n",
    "        \n",
    "        net.zeroGradParameters()\n",
    "        \n",
    "        # Forward\n",
    "        predictions = net.forward(x_batch)\n",
    "        loss = criterion.forward(predictions, y_batch)\n",
    "    \n",
    "        # Backward\n",
    "        dp = criterion.backward(predictions, y_batch)\n",
    "        net.backward(x_batch, dp)\n",
    "        \n",
    "        # Update weights\n",
    "        sgd(net.getParameters(), \n",
    "                     net.getGradParameters(), \n",
    "                     optimizer_config)      \n",
    "        \n",
    "        loss_history.append(loss)\n",
    "\n",
    "    # Visualize\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "        \n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"#iteration\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(loss_history, 'b')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Current loss: %f' % loss)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit classification (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваша задача - обучиться распознавать рукописные цифры из датасета MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# Fetch MNIST dataset and create a local copy.\n",
    "if os.path.exists('mnist.npz'):\n",
    "    with np.load('mnist.npz', 'r') as data:\n",
    "        X = data['X']\n",
    "        y = data['y']\n",
    "else:\n",
    "    mnist = fetch_mldata(\"mnist-original\")\n",
    "    X, y = mnist.data / 255.0, mnist.target\n",
    "    np.savez('mnist.npz', X=X, y=y)\n",
    "\n",
    "def one_hot_encode(data, n_classes=10):\n",
    "    n_objects = len(data)\n",
    "    data_encoded = np.zeros((n_objects, n_classes))\n",
    "    data_encoded[np.arange(n_objects), data.astype(int)] = 1\n",
    "    return data_encoded\n",
    "\n",
    "y = one_hot_encode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Попробуйте что-нибудь вроде этого:\n",
    "\n",
    "# net = Sequential()\n",
    "# net.add(Linear(784, 32))\n",
    "# net.add(Sigmoid())\n",
    "# net.add(Linear(32, 16))\n",
    "# net.add(SoftMax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с разным количеством скрытых слоев, с разным размером слоев, попробуйте поменять функцию активации. По итогу напишите отчет о проведенных экспериментах который включате в себя описание того, что вы сделали, и то, какую точность по метрике mse вы смогли получить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
